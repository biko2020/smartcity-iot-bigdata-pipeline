# ğŸ™ï¸ SmartCity IoT Big Data Pipeline

> **Production-grade real-time data platform for Smart Cities & Industry 4.0**

A complete end-to-end Big Data streaming solution showcasing modern data engineering practices: real-time ingestion, distributed stream processing, analytics-ready storage, and BI visualization â€” all containerized and production-oriented.

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![Spark](https://img.shields.io/badge/Apache%20Spark-3.4.1-orange.svg)](https://spark.apache.org/)
[![Kafka](https://img.shields.io/badge/Apache%20Kafka-Latest-black.svg)](https://kafka.apache.org/)
[![Docker](https://img.shields.io/badge/Docker-Compose-2496ED.svg)](https://www.docker.com/)

---

## ğŸ“Š Business Value

Smart cities and IoT platforms generate continuous high-velocity data streams from sensors monitoring traffic, air quality, temperature, noise, and infrastructure usage.

**This pipeline enables:**

âœ… Real-time ingestion of IoT events  
âœ… Scalable stream processing with Spark Structured Streaming  
âœ… Reliable data lake storage using Parquet  
âœ… Analytics-ready PostgreSQL warehouse  
âœ… Business dashboards for operational insights  
âœ… Automated orchestration & monitoring  

**Target Use Cases:**  
Smart Cities â€¢ Industry 4.0 â€¢ Environmental Monitoring â€¢ Traffic Analytics â€¢ Predictive Maintenance

---

## ğŸ—ï¸ Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   IoT Sensors / APIs        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Apache Kafka      â”‚  â† Real-time ingestion
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Spark Structured    â”‚  â† Stream processing
    â”‚    Streaming        â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Parquet Data Lake   â”‚  â† Scalable storage
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PostgreSQL          â”‚  â† Analytics / KPIs
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Apache Superset     â”‚  â† BI Dashboards
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Apache Airflow      â”‚  â† Orchestration
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Design Principles

- **Streaming-first architecture**
- **Fault-tolerant** (Spark checkpoints)
- **Horizontally scalable**
- **Cloud-agnostic** (AWS / GCP / Azure / on-prem)
- **Production-ready containerization**

---

## ğŸ“ Project Structure
```
smartcity-iot-bigdata-pipeline/
â”‚
â”œâ”€â”€ data/                           # Data Lake (mounted volume)
â”‚   â”œâ”€â”€ raw/                        # Kafka landing (optional)
â”‚   â””â”€â”€ processed/                  # Parquet from Spark Streaming
â”‚
â”œâ”€â”€ kafka/
â”‚   â””â”€â”€ producer_iot.py             # IoT / sensor simulator
â”‚
â”œâ”€â”€ spark/
â”‚   â””â”€â”€ streaming_job.py            # Spark Structured Streaming
â”‚
â”œâ”€â”€ superset/
â”‚   â””â”€â”€ dashboards/
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ load_postgres.py            # KPIs from Parquet â†’ PostgreSQL
â”‚
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/
â”‚       â””â”€â”€ smartcity_pipeline.py   # Orchestration
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Technology Stack

| Layer              | Technology                |
|--------------------|---------------------------|
| **Language**       | Python 3.10+              |
| **Streaming**      | Apache Kafka              |
| **Processing**     | Apache Spark 3.4.1        |
| **Orchestration**  | Apache Airflow            |
| **Storage**        | Parquet Data Lake         |
| **Analytics DB**   | PostgreSQL 15             |
| **Visualization**  | Apache Superset           |
| **Infrastructure** | Docker & Docker Compose   |

**Key Python Libraries:**
- `pyspark`
- `kafka-python`
- `pandas`
- `sqlalchemy`
- `psycopg2-binary`
- `pyarrow`

---

## ğŸš€ Quick Start

### Prerequisites

- Docker Engine 20.10+
- Docker Compose v2
- 8 GB RAM minimum (16 GB recommended)

### Deployment
```bash
git clone https://github.com/biko2020/smartcity-iot-bigdata-pipeline.git
cd smartcity-iot-bigdata-pipeline
docker compose -f docker/docker-compose.yml up -d
```

### Verify Services
```bash
docker ps
```

---

## â–¶ï¸ Pipeline Execution

**1ï¸âƒ£ Start IoT data simulation**
```bash
docker exec -it smartcity-kafka python3 /app/kafka/producer_iot.py
```

**2ï¸âƒ£ Launch Spark Streaming**
```bash
docker exec -it smartcity-spark spark-submit /app/spark/streaming_job.py
```

**3ï¸âƒ£ Load KPIs into PostgreSQL**
```bash
docker exec -it smartcity-spark python3 /app/scripts/load_postgres.py
```

---

## ğŸŒ Web Interfaces

| Service      | URL                          |
|--------------|------------------------------|
| **Spark UI** | http://localhost:4040        |
| **Airflow**  | http://localhost:8080        |
| **Superset** | http://localhost:8088        |

---

## ğŸ“ˆ KPIs & Analytics

- Average temperature per zone
- Pollution level trends
- Traffic density indicators
- Event throughput (msg/sec)
- Sensor activity & latency

---

## ğŸ¯ What This Project Proves

### Technical Skills

âœ” Kafka streaming ingestion  
âœ” Spark Structured Streaming  
âœ” Data Lake engineering  
âœ” OLAP-ready PostgreSQL modeling  
âœ” Airflow orchestration  
âœ” Dockerized production stack  

### Freelance-Ready Value

âœ” End-to-end delivery  
âœ” Scalable architecture  
âœ” Client-ready demo  
âœ” Cloud migration friendly  

---

## ğŸ’¼ Ideal Freelance Use

**Perfect for:**

- Smart City analytics platforms
- IoT data pipelines
- Real-time dashboards
- Kafka / Spark consulting
- Data platform MVPs

---

## ğŸ“ Contact

**AIT OUFKIR BRAHIM**  
*Big Data Engineer | Spark â€¢ Kafka â€¢ Airflow*

ğŸ“§ **Email:** [aitoufkirbrahimab@gmail.com](mailto:aitoufkirbrahimab@gmail.com)  
ğŸ’» **GitHub:** [@biko2020](https://github.com/biko2020)  
ğŸ’¼ **LinkedIn:** [brahim-aitoufkir](https://www.linkedin.com/in/brahim-aitoufkir-74506021a/)

---

## ğŸ“„ License

MIT License

---